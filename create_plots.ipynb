{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Plots\n",
    "Notebook to create all plots included in the paper, except for the DL experiments. The scripts ```LOVO_via_parent_adjustment.py```, ```LOVO_applied_to_RCD.py```, ```LOVO_via_LiNGAM.py``` need to be executed before to create the required CSV files with the simulation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from simulate_data import simulate_data\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "font = {'weight': 'bold', 'size': 16}\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How often are the lemmas successful in excluding edges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'PAG': 'Lemma 2 with PAGs',\n",
    "    'PAG_varying_q': 'Lemma 2 for PAGs (varying q)',\n",
    "    'ADMG': 'Lemma 2',\n",
    "    'GX_ADMG_G_DAG': 'Lemma 3',\n",
    "    'DAG': 'Lemma 7 with DAGs',\n",
    "    'CPDAG': 'Lemma 7 with CPDAGs'\n",
    "}\n",
    "for filename, title in settings.items(): # ['PAG', ]:\n",
    "    x_axis_q = filename == 'ADMG' or 'q' in filename\n",
    "    try:\n",
    "        results = pd.read_csv(f'simulation_results_camera_ready/excluded_edges_{filename}.csv')\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "    nr_potential_edges = math.comb(10, 2)\n",
    "    grouped_results = results.groupby('q' if x_axis_q else 'p').agg(\n",
    "        percentage_excluded_edges=('number_excluded_edges', lambda x: x.mean() ), \n",
    "        count_no_excluded_edges=('number_excluded_edges', lambda x: (x == 0).sum()) \n",
    "    ).reset_index()\n",
    "\n",
    "    plt.plot(grouped_results['q' if x_axis_q else 'p'], grouped_results['percentage_excluded_edges'], marker='o', label='Percentage of excluded edges')\n",
    "    \n",
    "    ps = np.linspace(0.1, 0.9, 100)\n",
    "    upper_bound = (1-0.3)*(1-ps)*nr_potential_edges if x_axis_q else nr_potential_edges - nr_potential_edges*ps\n",
    "    plt.plot(ps, upper_bound, color='grey', zorder=-1)\n",
    "    plt.xlabel('Bidirected edge probability' if x_axis_q else 'Directed edge probability')\n",
    "    plt.ylabel('Number of excluded edges')\n",
    "    plt.title(title, pad=10)\n",
    "    plt.ylim(-1, 41)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'simulation_results_camera_ready/mean_excluded_edges_{filename}.eps')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(grouped_results['q' if x_axis_q else 'p'], grouped_results['count_no_excluded_edges'], marker='o', color='tab:orange')\n",
    "    plt.xlabel('Bidirected edge probability' if x_axis_q else 'Directed edge probability')\n",
    "    plt.ylabel('Runs without excluded edges')\n",
    "    plt.title(title, pad=10)\n",
    "    plt.ylim(-25, 1000)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'simulation_results_camera_ready/no_excluded_edges_{filename}.eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOVO via Parent Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'LOVO_via_LiNGAM': 'LOVO via LiNGAM',\n",
    "    'GX_ADMG_G_DAG': 'Parent adjustment (Lemma 3)',\n",
    "    'ADMG': 'Parent adjustment (Lemma 2)',\n",
    "    'CPDAG': 'Path adjustment (CPDAGs)',\n",
    "    'PAG': 'Path adjustment (PAGs)',\n",
    "    'DAG': 'Parent adjustment (DAGs)'\n",
    "\n",
    "}\n",
    "\n",
    "for setting, title in settings.items():\n",
    "    results = pd.read_csv('simulation_results_1st_version/LOVO_via_LiNGAM_p=0.3.csv') if setting == 'LOVO_via_LiNGAM' else pd.read_csv(f'simulation_results/parent_adj_{setting}.csv')\n",
    "    results_grouped = results.groupby('sim').agg({'lovo_error': ['mean', 'count'], 'baseline_error': 'mean'})\n",
    "    results_grouped.columns = ['lovo_error', 'nr_edges_considered', 'baseline_error']\n",
    "    baseline_errors, lovo_errors = results_grouped['baseline_error'], results_grouped['lovo_error']\n",
    "    color = 'tab:orange' if setting == 'LOVO_via_LiNGAM' else 'tab:blue'\n",
    "    plt.scatter(baseline_errors, lovo_errors, color=color, alpha=.8)\n",
    "    dotted_line = np.linspace(0, 0.23, 100)\n",
    "    plt.plot(dotted_line, dotted_line, color='black', zorder=-1)\n",
    "    plt.xlabel('Baseline loss')\n",
    "    plt.ylabel('LOVO loss')\n",
    "    plt.title(title, pad=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'simulation_results/parent_adj_{setting}.eps') \n",
    "    plt.show()\n",
    "\n",
    "    print(f'LOVO loss higher in {np.mean(lovo_errors > baseline_errors)*100} % of the cases')\n",
    "    print(f'No prediction made in {np.mean(results_grouped[\"lovo_error\"].isna())*100} % of the cases')\n",
    "    print(f'Average number of edges considered {np.mean(results_grouped[\"nr_edges_considered\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DirectLiNGAM and RCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg in ['RCD', 'DirectLiNGAM']: #\n",
    "    p = 0.5 if alg == 'DirectLiNGAM' else 0.3\n",
    "    nr_nodes = 10 if alg == 'DirectLiNGAM' else 5\n",
    "    results = pd.read_csv(f\"simulation_results_camera_ready/{alg}_nr_nodes={nr_nodes}_p={p}_reps=1000_varying_nlearn.csv\")\n",
    "    results_grouped = results[(~results[f'lovo_error'].isna())].groupby(['simulation', 'n_learn']).agg({'lovo_error': 'mean', 'baseline_error': 'mean', 'SHD': 'mean', 'edge_exists': 'mean'})\n",
    "\n",
    "    for n_learn in results['n_learn'].unique():\n",
    "        results_grouped_n_learn = results_grouped.loc(axis=0)[:, n_learn]\n",
    "        plt.scatter(results_grouped_n_learn[f'baseline_error'], results_grouped_n_learn[f'lovo_error'], alpha=.8, s=20, color='tab:orange')# \n",
    "        dotted_line = np.linspace(0, max(list(results_grouped[f'lovo_error'])+list(results_grouped[f'baseline_error'])), 100)\n",
    "        plt.plot(dotted_line, dotted_line, color='black', zorder=-1)\n",
    "        plt.xlabel('Baseline loss')\n",
    "        plt.ylabel('Parent adjustment LOVO loss')\n",
    "        plt.title(f'{alg}, n_learn={n_learn}', pad=10)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'simulation_results_camera_ready/{alg}_{n_learn}.eps')\n",
    "        plt.show()\n",
    "        print(f'SHD: {np.mean(results[results['n_learn']==n_learn][\"SHD\"])/2}')\n",
    "        print(f'LOVO loss higher in {np.mean(results_grouped_n_learn[f'lovo_error'] > results_grouped_n_learn[f'baseline_error'])*100} % of the cases')\n",
    "        print(f'No prediction made in {(1000 - len(results_grouped_n_learn))/10} % of the cases')\n",
    "\n",
    "    for measure in ['SHD', 'edge_exists']:\n",
    "        rho, pval = spearmanr(results_grouped[measure], results_grouped[f'lovo_error'])\n",
    "        lovo_errors =  results_grouped[f'lovo_error']\n",
    "        plt.figure(figsize=(5.5,5.5))\n",
    "        if alg == 'DirectLiNGAM':\n",
    "            plt.ylim(top=0.21)\n",
    "            plt.yticks(np.linspace(0, 0.2, 5))\n",
    "        plt.scatter(results_grouped[measure], lovo_errors, alpha=.8, color='tab:orange')\n",
    "        plt.xlabel('Edge exists' if measure=='edge_exists' else 'SHD')\n",
    "        plt.ylabel('LOVO loss')\n",
    "        plt.title(f\"{alg}, $\\\\rho$={rho:.2f}\", pad=10)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'simulation_results_camera_ready/{alg}_corr_{measure}.eps') \n",
    "        plt.show()\n",
    "        print(f'{alg}: Correlation of {measure} with lovo error is', spearmanr(results_grouped[measure], results_grouped[f'lovo_error']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "for df in ['DirectLiNGAM_nr_nodes=10_p=0.5_compatibility_varying_nlearn.csv',\n",
    "           'RCD_nr_nodes=5_p=0.3_compatibility_varying_nlearn.csv']:\n",
    "    data = pd.read_csv(f'simulation_results/{df}')\n",
    "    data = data.dropna()\n",
    "    data['lovo_loss'] = data['lovo_error'] - data['baseline_error']\n",
    "    rho, pval = spearmanr(data['graphical_sc'], data['lovo_error'])\n",
    "    plt.scatter(data['graphical_sc'], data['lovo_loss'])\n",
    "    plt.xlabel(\"Self-compatibility score\")\n",
    "    plt.ylabel(\"Lovo loss\")\n",
    "    alg_name = df.split('_')[0]\n",
    "    print(rho, pval)\n",
    "    plt.title(f\"{alg_name}, $\\\\rho$={rho:.2f}\", pad=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'simulation_results/comparison_self_compatibility_{alg_name}.eps')\n",
    "    plt.show()\n",
    "    \n",
    "    print(data[['graphical_sc', 'lovo_error']].corr(method='kendall'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
